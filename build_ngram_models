#!/bin/bash

# Estimate an N-gram kneser-ney language model from the raw text files.
#
# Usage:
# $ ./build_ngram_models [N] [list of model types...]
#
# Example:
# $ ./build_ngram_models 4 lower_chars upper_chars


java_path="/u/teammco/Documents/Java/jdk1.8.0_40/bin/java"
cp="berkeleylm-1.1.6/src"


if [ -z "$1" ]; then
    N=3;
else
    N=$1
fi


if [ -z "$2" ]; then
    types=(upper_words lower_words upper_chars lower_chars)
else
    tmp=($@)
    types=(${tmp[@]:1})
fi


echo "Generating $N-Gram models for ${types[*]}..."


classes=(ham spam)
for t in ${types[*]}
do
    for class in ${classes[*]}
    do
        model="$t"_"$class"
        in_file="Data/NGramTrain/$model"
        out_file="Models/N_"$N"_$model"
        arpa_file="$out_file.arpa"
        bin_file="$out_file.binary"
        echo "Generating $out_file..."
        $java_path -ea -mx1000m -server -cp $cp edu.berkeley.nlp.lm.io.MakeKneserNeyArpaFromText $N $arpa_file $in_file
        $java_path -ea -mx1000m -server -cp $cp edu.berkeley.nlp.lm.io.MakeLmBinaryFromArpa $arpa_file $bin_file
    done
done
