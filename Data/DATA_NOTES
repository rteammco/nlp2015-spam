Data Split: 81/9/10
    Total:      75419   (100%)  1 to 75419
    Train:      67877   (90%)   1 to 67877
      NG-train: 61089   (81%)   1 to 61089
      NG-eval:  6788    (9%)    61090 to 67877
    Test:       7542    (10%)   67878 to 75419


Data Split: 60/30/10
    Total:      75419   (100%)  1 to 75419
    Train:      67877   (90%)   1 to 67877
      NG-train: 45252   (60%)   1 to 45252
      NG-eval:  22625   (30%)   45253 to 67877
    Test:       7542    (10%)   67878 to 75419



*_bulk.arff:    Data output by the Python preprocessor. This data is just
                full messages per feature.
*_std.arff:     Data filtered by Weka, converting the full sentences into
                a standardized bag of words model. Both training and testing
                data sets must be generated simultaneously for the sets to be
                standardized and thus work with Weka's classifiers.
NGram/*:        Full text corpa (filtered) but with no stopwords removed.
                The purpose of these files is to train NGram models and
                evaluate the test data on them.



Scrap:
*_nostop.arff:  The old standardized files that have all the stopwords in them.
                The new std files should have stopwords removed.
