#!/bin/bash

# Generates all possible data sets for the N-Gram training sets:
#   {regular words, lowercase words, regular characters, lowercase characters}
# Each iteration will produce two files: one for spam messages and another
# for ham messages, prefaced with "spam_" and "ham_", respectively.
# e.g. the first line will produce the following two files:
#   spam_ngram_upper_words
#   ham_ngram_upper_words


# Training and testing data ranges
train_start=1
train_end=60000
test_start=60001
test_end=75419

data_dir="Data/NGram"
cmd="python preprocess.py trec07p"

# All the types of NGram models we will use:
params=(
    "--ngrams"
    "--ngrams --ngram-lower"
    "--ngrams --ngram-chars"
    "--ngrams --ngram-lower --ngram-chars"
)
fnames=(
    "upper_words"
    "lower_words"
    "upper_chars"
    "lower_chars"
)

# Compile the preprocessed data files for all test and train instances:
for ((i = 0; i < ${#params[@]}; i++))
do
    param=${params[$i]}
    fname=${fnames[$i]}
    echo "Parameter: $param ($fname)"

    echo "Generating for training data: $train_start - $train_end"
    train_fname="$data_dir/train_$fname"
    $cmd $train_start $train_end $train_fname $param

    echo "Generating for testing data: $test_start - $test_end"
    test_fname="$data_dir/test_$fname"
    $cmd $test_start $test_end $test_fname $param

    echo ""
done

echo "All done. SUCCESS!"
