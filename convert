#!/bin/bash

# This script converts the training and testing data sets that are produced
# by the Python "preprocessor.py" code into a format usable by Weka. Both
# training and testing files are necessary so they can be converted and
# standardized for the classifier.
#
# It is assumed that the training data and testing data files produced by
# the preprocessor code are available in the following files:
#   Data/train_bulk.arff
#   Data/test_bulk.arff
#
# Once converted, the files ready for the classifier will be as follows:
#   Data/train_std.arff
#   Data/test_std.arff



in_dir="Data/Split_60_30_10"
bulk_fname="BoW_meta_img_bulk"
std_fname="BoW_meta_img_std"



train_bulk="${in_dir}/${bulk_fname}_train.arff"
test_bulk="${in_dir}/${bulk_fname}_test.arff"
train_std="${in_dir}/${std_fname}_train.arff"
test_std="${in_dir}/${std_fname}_test.arff"

filter="weka.filters.unsupervised.attribute.StringToWordVector"

cp_weka="weka-3-6-12/weka.jar"
cp_proj="."

# Optional flags:
#   -C  labels include word counts, not just binary (is word there or not).
#   -L  converts everything to lower case.
#   -S  stopwords are removed (doesn't really work though).
#   -b  bulk (allows both training and testing conversion).
java -Xmx1024m -cp "$cp_weka:$cp_proj" $filter -C -L -b -i $train_bulk -o $train_std -r $test_bulk -s $test_std
