#!/bin/bash

# Evaluates all messages, training and testing, for a single model, and puts
# the scores into a single output file to be processed later by other
# preprocessing scripts.
#
# Example usage:
#  $ ./eval_all_ngrams 3 lower_chars ham


JAVA_EXE="/u/teammco/Documents/Java/jdk1.8.0_40/bin/java"
CMD="$JAVA_EXE -ea -mx1000m -server -cp berkeleylm-1.1.6/src edu.berkeley.nlp.lm.io.ComputeLogProbabilityOfTextStream"


# <<< DATA RANGE >>>
split_81_9_10() {
    train_start=61090
    train_end=67877
    test_start=67878
    test_end=75419
    split="Split_81_9_10"
}

split_60_30_10() {
    train_start=45253
    train_end=67877
    test_start=67878
    test_end=75419
    split="Split_60_30_10"
}

split_60_30_10
# <<< DATA RANGE >>>
train_dir="Data/NGramTrain/$split"
model_dir="Models/$split"


N=$1
model=$2
class=$3

if [ -z "${N}" ] || [ -z "${model}" ] || [ -z "${class}" ] ; then
    echo "Usage: \$ ./eval_ngram <N> <model> <class>"
    echo "e.g.   \$ ./eval_ngram 3 lower_words spam"
    exit
fi


train_path="$train_dir/${model}"
test_path="Data/NGramTest/${model}"

full_model="N_${N}_${model}_${class}"
binary="$model_dir/${full_model}.binary"

outfile="$model_dir/Evaluations/$full_model"


mkdir -p $model_dir/Evaluations
rm -f $outfile


for msg in $(seq $train_start $train_end); do
    $CMD $binary $train_path/message_$msg 1>> $outfile;
done

for msg in $(seq $test_start $test_end); do
    $CMD $binary $test_path/message_$msg 1>> $outfile;
done
